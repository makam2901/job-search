# name: Sri Manikesh Makam
# contact:
#   email: makamsrimanikesh@outlook.com
#   phone: "+1 (551) 267-5388"
#   location: San Francisco, CA
#   linkedin: https://www.linkedin.com/in/manikesh-makam-31804a210/
#   github: https://github.com/makam2901
#   medium: https://medium.com/@manikeshmakam

# education:
#   - degree: Master of Science in Data Science
#     school: University of San Francisco
#     location: San Francisco, USA
#     dates: Jul 2024 - Jun 2025
#     context: "Relevant coursework includes Inferential Statistics, Machine Learning, Data Acquisition, Data Structures and Algorithms, Distributed Systems, Relational Databases (SQL), Data Visualization, A/B Testing, Time Series Analysis, Deep Learning, Ethics in Data Science."
#   - degree: Bachelor of Technology in Aerospace Engineering
#     school: Indian Institute of Technology
#     location: Kanpur, India
#     dates: Jul 2018 - Jun 2022

# experience:
#   - title: Data Scientist Intern
#     company: DRINKS
#     location: San Francisco, USA
#     dates: Oct 2024 - Jun 2025
#     context: "Built a context aware AI wine recommendation system using OpenAI LLMs, retrieval augmented generation architecture, and Flask for backend inference. Engineered Pinecone based vector search with multi index setup on AWS S3, reducing latency by 80 percent while handling over ten thousand embeddings. Integrated Hugging Face cross encoder reranker to improve semantic similarity and top k retrieval precision. Developed modular AWS Bedrock AI Agent with preprocessing layers, advanced prompt templates, and knowledge base retrieval orchestration. Deployed Lambda functions to extract and format API ready responses for seamless integration into a JavaScript based ecommerce frontend. Delivered technical presentations as intern to CTO and Cofounder, leading to company wide adoption and deployment as an AI powered user facing product."
#   - title: Principal Analyst
#     company: AB InBev
#     location: Bangalore, India
#     dates: Aug 2022 - Jun 2024
#     context: "Led a team of 4 to eliminate manual Excel-based workflows using Python, Pandas, and Airflow, resulting in $500,000 in annual savings across reporting cycles. Designed and deployed 8 interactive Power BI dashboards for executive KPIs, reducing manual workload and reporting errors by 80%. Built scalable ETL pipelines integrating SQL Server and Salesforce to automate 5 recurring reports and streamline over 10 datasets for supply chain analytics. Created advanced SQL scripts using CTEs, window functions, and aggregation logic to harmonize metrics across regional operations. Developed Excel VBA macros and Python utilities to accelerate monthly financial close, saving $1,000 in manual effort and improving data accuracy. Standardized 15 data ingestion workflows and mapped 20 cross-functional data processes, improving governance and documentation clarity. Served as Salesforce reporting administrator, enabling automated triggers and integrating real-time reporting into analytics pipelines. Executed 5 structured A/B test cycles and validated uplift using SQL-based significance testing, improving BDR platform stability and increasing CSAT scores by 15%."
#   - title: Data Science Intern
#     company: Janta Ka Mood
#     location: Kanpur, India
#     dates: May 2021 - Jul 2021
#     context: "Processed 5.2M+ voter records using Microsoft SQL Server, optimizing data extraction for high-volume analysis and reporting. Designed interactive RStudio dashboard to show voter demographics, boosting efficiency by 40% by enabling data-driven decisions."

# projects:
#   - title: AI Fantasy Team Predictor
#     dates: Mar 2025 - May 2025
#     context: "Developed a full-stack AI-powered fantasy cricket platform using Python, FastAPI, and Streamlit, delivering real-time data driven team recommendations. Engineered and fine-tuned GradientBoostingRegressor models with feature engineering and hyperparameter optimization using RandomizedSearchCV, enhancing player fantasy point predictions. Integrated Google Gemini LLM to create a conversational AI agent, providing interactive cricket insights and boosting user engagement. Designed and implemented MLOps workflows with MLflow for experiment tracking, model versioning, and deployment automation, ensuring reproducibility and continuous improvement. Containerized and deployed the application on Google Kubernetes Engine with Docker and Kubernetes, leveraging GCP for scalable cloud native orchestration. Architected secure, scalable GCP infrastructure using Cloud Storage for data persistence and Secret Manager for credential management."
#   - title: Longitudinal Growth Forecasting
#     dates: Feb 2025 - Mar 2025
#     context: "Developed a hybrid ML pipeline combining CatBoost regressors and Preece-Baines biological models to predict adolescent growth trajectories across age intervals. Conducted time-series aware feature engineering using fixed age grids and growth velocity metrics to normalize irregular measurement intervals. Addressed longitudinal data missingness using KNN and biologically informed imputation strategies for accurate, realistic model inputs. Performed hyperparameter tuning with RandomizedSearchCV and time-series cross-validation, improving RMSE by 18% and enhancing model generalization. Interpreted model outputs using SHAP values and partial dependence plots, identifying key predictors such as parental height and growth rate trends."
#   - title: US Census Data Processing Pipeline
#     dates: Jan 2025
#     context: "Designed and implemented a scalable, automated ETL pipeline to process 650 GB of annual US Census data using PySpark, Airflow, and GCP Composer. Orchestrated end-to-end data workflows with Apache Airflow DAGs, ensuring reliable ingestion, transformation, and storage in Google Cloud Storage. Built Python-based extraction modules using Selenium and BeautifulSoup to scrape census datasets from public health databases. Performed data cleaning and transformation with Pandas, applying systematic rules for missing data handling and schema standardization. Loaded cleaned data into MongoDB Atlas and developed aggregation pipelines to derive key demographic metrics such as population distribution and unemployment rates. Automated generation of visual analytics using Matplotlib and stored outputs in GCS to support downstream demographic modeling."
#   - title: AI Speech Emotion Recognition System
#     dates: Mar 2025 - May 2025
#     context: "Developed and deployed an end-to-end deep learning pipeline for speech emotion recognition, achieving 89% accuracy on a multi-class audio classification task. Designed and trained three PyTorch-based neural network architectures (CNN, CRNN, and CNN-LSTM Fusion) to benchmark performance across spatial and temporal features. Engineered automated hyperparameter tuning workflows using Optuna, optimizing over 50 trials to enhance generalization and reduce overfitting. Processed and integrated four open-source emotion datasets (RAVDESS, CREMA-D, TESS, SAVEE) and standardized MFCC features using Librosa and Pandas. Built modular training, evaluation, and inference pipelines with model serialization for production readiness using PyTorch and Joblib. Conducted detailed model evaluation using Scikit-learn, including confusion matrices and per-class metrics to ensure robust performance across emotions."
#   - title: AI Photo Colorizer
#     dates: Jan 2025 - Feb 2025
#     context: "Designed and deployed a full-stack deep learning application to colorize grayscale images using a custom UNet architecture built in PyTorch. Engineered an encoder-decoder model with skip connections to map grayscale inputs to Lab color channels, optimizing realism through L1 loss minimization. Processed large-scale image data from the COCO dataset with custom OpenCV pipelines and PyTorch DataLoaders, enhancing preprocessing efficiency and model throughput. Built a Flask web app with HTML/CSS frontend to deliver real-time image colorization through a clean and interactive user interface. Managed model inference, image postprocessing, and file handling in a modular backend architecture, supporting smooth user uploads and downloads. Ensured modular code design, version control, and reproducibility through well-structured GitHub repository and training-validation workflow separation."

# certifications:
#   - title: AWS Certified AI Practitioner
#     issuer: Amazon Web Services
#     date: Oct 2024
#     description:
#       - Expertise in AWS AI and ML - Skilled in Amazon SageMaker, Bedrock, and AWS AI Services for model training and development.
#       - Generative AI and Prompt Engineering - Experience with Amazon Bedrock, Amazon Q, and LLM applications and techniques.
#       - AI Security and Deployment - Knowledge of AWS IAM policies, security services, AI governance, and scalable cloud deployments.


name: Sri Manikesh Makam
contact:
  email: makamsrimanikesh@outlook.com
  phone: "+1 (551) 267-5388"
  location: San Francisco, CA
  linkedin: https://www.linkedin.com/in/manikesh-makam-31804a210/
  github: https://github.com/makam2901
  medium: https://medium.com/@manikeshmakam

education:
  - degree: Master of Science in Data Science
    school: University of San Francisco
    location: San Francisco, USA
    dates: Jul 2024 - Jun 2025
    courses: "Inferential Statistics, Machine Learning, Data Acquisition, Data Structures and Algorithms, Distributed Systems, Relational Databases (SQL), Data Visualization, A/B Testing, Time Series Analysis, Deep Learning, Ethics in Data Science."
  - degree: Bachelor of Technology in Aerospace Engineering
    school: Indian Institute of Technology
    location: Kanpur, India
    dates: Jul 2018 - Jun 2022
skills:
  - Languages: Python, SQL, R, Bash, VBA, JavaScript
  - ML_Techniques: Regression, Classification, Clustering, Time Series, NLP, Deep Learning, A/B Testing, Hyperparameter Tuning, Model Monitoring
  - Libraries: scikit-learn, TensorFlow, PyTorch, XGBoost, CatBoost, pandas, NumPy, Seaborn, Matplotlib, Langchain, FAISS
  - Tools: Airflow, Spark, PySpark, Docker, Flask, FastAPI, Selenium, Git, Jupyter, VSCode, MLflow, Metaflow, Streamlit, HTML, Node.js, React.js
  - Cloud: AWS (Lambda, S3, Bedrock), GCP (GCS, Composer, Kubernetes, BigQuery), Pinecone
  - DevOps: Terraform, GitHub Actions, CI/CD, MLOps Automation
  - LLMs_AI: OpenAI, Hugging Face, Gemini, Langflow, RAG, Prompt Engineering, AI Agents, Vector DBs, Document Retrieval
  - Databases: PostgreSQL, MySQL, SQL Server, MongoDB
  - Testing: Pytest, Great Expectations, Evidently AI, Model Validation
  - Visualization: Tableau, Power BI, Excel, R Shiny
  - Business: KPI Analysis, Process Optimization, Stakeholder Communication, Project Management, Documentation, Data Governance

experience:
  - title: Data Scientist Intern
    company: DRINKS
    location: San Francisco, USA
    dates: Oct 2024 - Jun 2025
    context: "Built an AI-powered wine recommendation system using OpenAI LLMs, RAG architecture, Pinecone vector search, and AWS Bedrock for scalable, low-latency retrieval. Deployed backend with Flask and Lambda, integrated with a JavaScript frontend, and drove company-wide adoption through executive presentations."
  - title: Principal Analyst
    company: AB InBev
    location: Bangalore, India
    dates: Aug 2022 - Jun 2024
    context: "Led end-to-end automation of reporting workflows using Python, Airflow, Power BI, Salesforce automations, and VBA, saving $500K annually and reducing errors by 80%. Built scalable ETL pipelines, standardized data processes, and ran SQL-based A/B tests that improved CSAT by 15%. Managed cross-functional projects and collaborated with stakeholders to align data solutions with business goals."
  - title: Data Science Intern
    company: Janta Ka Mood
    location: Kanpur, India
    dates: May 2021 - Jul 2021
    context: "Processed over 5.2M voter records with SQL Server and built an interactive RStudio dashboard, improving demographic analysis efficiency by 40%."

projects:
  - title: AI Fantasy Team Predictor
    dates: Mar 2025 - May 2025
    context: "Built a full-stack AI fantasy cricket platform with FastAPI, Streamlit, and GradientBoosting models for real-time team recommendations. Integrated Gemini LLM for conversational insights and deployed the system on GCP with Docker, Kubernetes, and MLflow-enabled MLOps."
  - title: Longitudinal Growth Forecasting
    dates: Feb 2025 - Mar 2025
    context: "Built a hybrid ML pipeline using CatBoost and Preece-Baines models to forecast adolescent growth, improving RMSE by 18%. Applied time-series feature engineering, imputation strategies, and SHAP-based interpretation to enhance accuracy and model insights."
  - title: US Census Data Processing Pipeline
    dates: Jan 2025
    context: "Built a scalable ETL pipeline to process 650 GB of US Census data using PySpark, Airflow, and GCP, enabling end-to-end automation and reliable data storage. Scraped, cleaned, and transformed public datasets, loaded outputs into MongoDB, and generated visual analytics to support demographic modeling."
  - title: AI Speech Emotion Recognition System
    dates: Mar 2025 - May 2025
    context: "Developed a deep learning pipeline for speech emotion recognition using PyTorch, achieving 89% accuracy across multiple architectures (CNN, CRNN, CNN-LSTM). Automated hyperparameter tuning with Optuna, standardized MFCC features from 4 datasets, and built production-ready inference pipelines."
  - title: AI Photo Colorizer
    dates: Jan 2025 - Feb 2025
    context: "Developed a full-stack deep learning app for image colorization using a custom UNet in PyTorch, optimized with L1 loss and OpenCV pipelines. Deployed the model via a Flask web app with real-time inference, modular backend, and an interactive UI for smooth image uploads and downloads."

certifications:
  - title: AWS Certified AI Practitioner
    issuer: Amazon Web Services
    date: Oct 2024
    description:
      - Expertise in AWS AI and ML - Skilled in Amazon SageMaker, Bedrock, and AWS AI Services for model training and development.
      - Generative AI and Prompt Engineering - Experience with Amazon Bedrock, Amazon Q, and LLM applications and techniques.
      - AI Security and Deployment - Knowledge of AWS IAM policies, security services, AI governance, and scalable cloud deployments.