name: Sri Manikesh Makam
contact:
  email: makamsrimanikesh@outlook.com
  phone: "+1 (551) 267-5388"
  location: San Francisco, CA
  linkedin: https://www.linkedin.com/in/manikesh-makam-31804a210/
  github: https://github.com/makam2901
  medium: https://medium.com/@manikeshmakam

summary: >
  Data Scientist with over three years of experience in Python, SQL, machine learning, data engineering, and statistical modeling.
  Skilled in designing and deploying scalable ML systems and automating data pipelines to drive measurable business value.
  Experienced in collaborating with cross-functional stakeholders to deliver insights and build high-impact solutions.
  Proficient in cloud platforms including AWS and GCP, and familiar with A/B testing, LLM integration, and MLOps practices.

skills:
  Programming Languages: Python, SQL, R, Bash, VBA, JavaScript, TypeScript
  ML and Modeling: Regression, Classification, Clustering, Time Series Forecasting, NLP, Deep Learning, A/B Testing, Hyperparameter Tuning, Model Monitoring
  Libraries and Frameworks: scikit-learn, TensorFlow, PyTorch, XGBoost, CatBoost, pandas, NumPy, Seaborn, Matplotlib, Langchain, LlamaIndex, FAISS
  Tools and Platforms: Airflow, Spark, PySpark, Docker, Docker Compose, Flask, FastAPI, Selenium, Git, Jupyter, VSCode, MLflow, Metaflow, dbt
  Cloud and DevOps: AWS (Lambda, S3, Bedrock), GCP (GCS, Composer, Kubernetes, BigQuery), Pinecone, Terraform, GitHub Actions, Streamlit, HTML, Node.js, React.js
  LLMs and AI: OpenAI, Hugging Face, Gemini, Langflow, RAG, Prompt Engineering, AI Agents, Vector Databases, Document Retrieval
  Databases: PostgreSQL, MySQL, Microsoft SQL Server, MongoDB
  Testing and MLOps: Pytest, Great Expectations, Evidently AI, Model Validation, CI/CD Pipelines, MLOps Automation
  Visualization: Tableau, Power BI, Excel, R Shiny
  Business Skills: KPI Analysis, Process Optimization, Stakeholder Communication, Project Management, Documentation, Data Governance

experience:
  - title: Data Scientist
    company: DRINKS
    location: San Francisco, USA
    dates: Oct 2024 - Jun 2025
    bullets:
      - Built a context aware AI wine recommendation system using OpenAI LLMs, retrieval augmented generation architecture, and Flask for backend inference.
      - Engineered Pinecone based vector search with multi index setup on AWS S3, reducing latency by 80 percent while handling over ten thousand embeddings.
      - Integrated Hugging Face cross encoder reranker to improve semantic similarity and top k retrieval precision.
      - Developed modular AWS Bedrock AI Agent with preprocessing layers, advanced prompt templates, and knowledge base retrieval orchestration.
      - Deployed Lambda functions to extract and format API ready responses for seamless integration into a JavaScript based ecommerce frontend.
      - Delivered technical presentations as intern to CTO and Cofounder, leading to company wide adoption and deployment as an AI powered user facing product.

  - title: Principal Analyst
    company: AB InBev
    location: Bangalore, India
    dates: Aug 2022 - Jun 2024
    bullets:
      - Led a team of 4 to eliminate manual Excel-based workflows using Python, Pandas, and Airflow, resulting in $500,000 in annual savings across reporting cycles.
      - Designed and deployed 8 interactive Power BI dashboards for executive KPIs, reducing manual workload and reporting errors by 80%.
      - Built scalable ETL pipelines integrating SQL Server and Salesforce to automate 5 recurring reports and streamline over 10 datasets for supply chain analytics.
      - Created advanced SQL scripts using CTEs, window functions, and aggregation logic to harmonize metrics across regional operations.
      - Developed Excel VBA macros and Python utilities to accelerate monthly financial close, saving $1,000 in manual effort and improving data accuracy.
      - Standardized 15 data ingestion workflows and mapped 20 cross-functional data processes, improving governance and documentation clarity.
      - Served as Salesforce reporting administrator, enabling automated triggers and integrating real-time reporting into analytics pipelines.
      - Executed 5 structured A/B test cycles and validated uplift using SQL-based significance testing, improving BDR platform stability and increasing CSAT scores by 15%.

  - title: Data Science Intern
    company: Janta Ka Mood
    location: Kanpur, India
    dates: May 2021 - Jul 2021
    bullets:
      - Processed 5.2M+ voter records using Microsoft SQL Server, optimizing data extraction for high-volume analysis and reporting.
      - Designed interactive RStudio dashboard to show voter demographics, boosting efficiency by 40% by enabling data-driven decisions.

education:
  - degree: Master of Science in Data Science
    school: University of San Francisco
    location: San Francisco, USA
    dates: Jul 2024 - Jun 2025
    details: >
      Relevant coursework includes Inferential Statistics, Machine Learning, Data Acquisition, Data Structures and Algorithms, Distributed Systems, Relational Databases (SQL), Data Visualization, A/B Testing, Time Series Analysis, Deep Learning, Ethics in Data Science.

  - degree: Bachelor of Technology in Aerospace Engineering
    school: Indian Institute of Technology
    location: Kanpur, India
    dates: Jul 2018 - Jun 2022

projects:
  - title: AI Fantasy Team Predictor
    dates: Mar 2025 - May 2025
    bullets:
      - Developed a full-stack AI-powered fantasy cricket platform using Python, FastAPI, and Streamlit, delivering real-time data driven team recommendations.
      - Engineered and fine-tuned GradientBoostingRegressor models with feature engineering and hyperparameter optimization using RandomizedSearchCV, enhancing player fantasy point predictions.
      - Integrated Google Gemini LLM to create a conversational AI agent, providing interactive cricket insights and boosting user engagement.
      - Designed and implemented MLOps workflows with MLflow for experiment tracking, model versioning, and deployment automation, ensuring reproducibility and continuous improvement.
      - Containerized and deployed the application on Google Kubernetes Engine with Docker and Kubernetes, leveraging GCP for scalable cloud native orchestration.
      - Architected secure, scalable GCP infrastructure using Cloud Storage for data persistence and Secret Manager for credential management.

  - title: Longitudinal Growth Forecasting
    dates: Feb 2025 - Mar 2025
    bullets:
      - Developed a hybrid ML pipeline combining CatBoost regressors and Preece-Baines biological models to predict adolescent growth trajectories across age intervals.
      - Conducted time-series aware feature engineering using fixed age grids and growth velocity metrics to normalize irregular measurement intervals.
      - Addressed longitudinal data missingness using KNN and biologically informed imputation strategies for accurate, realistic model inputs.
      - Performed hyperparameter tuning with RandomizedSearchCV and time-series cross-validation, improving RMSE by 18% and enhancing model generalization.
      - Interpreted model outputs using SHAP values and partial dependence plots, identifying key predictors such as parental height and growth rate trends.

  - title: US Census Data Processing Pipeline
    dates: Jan 2025
    bullets:
      - Designed and implemented a scalable, automated ETL pipeline to process 650 GB of annual US Census data using PySpark, Airflow, and GCP Composer.
      - Orchestrated end-to-end data workflows with Apache Airflow DAGs, ensuring reliable ingestion, transformation, and storage in Google Cloud Storage.
      - Built Python-based extraction modules using Selenium and BeautifulSoup to scrape census datasets from public health databases.
      - Performed data cleaning and transformation with Pandas, applying systematic rules for missing data handling and schema standardization.
      - Loaded cleaned data into MongoDB Atlas and developed aggregation pipelines to derive key demographic metrics such as population distribution and unemployment rates.
      - Automated generation of visual analytics using Matplotlib and stored outputs in GCS to support downstream demographic modeling.

  - title: AI Speech Emotion Recognition System
    dates: Mar 2025 - May 2025
    bullets:
      - Developed and deployed an end-to-end deep learning pipeline for speech emotion recognition, achieving 89% accuracy on a multi-class audio classification task.
      - Designed and trained three PyTorch-based neural network architectures (CNN, CRNN, and CNN-LSTM Fusion) to benchmark performance across spatial and temporal features.
      - Engineered automated hyperparameter tuning workflows using Optuna, optimizing over 50 trials to enhance generalization and reduce overfitting.
      - Processed and integrated four open-source emotion datasets (RAVDESS, CREMA-D, TESS, SAVEE) and standardized MFCC features using Librosa and Pandas.
      - Built modular training, evaluation, and inference pipelines with model serialization for production readiness using PyTorch and Joblib.
      - Conducted detailed model evaluation using Scikit-learn, including confusion matrices and per-class metrics to ensure robust performance across emotions.

  - title: AI Photo Colorizer
    dates: Jan 2025 - Feb 2025
    bullets:
      - Designed and deployed a full-stack deep learning application to colorize grayscale images using a custom UNet architecture built in PyTorch.
      - Engineered an encoder-decoder model with skip connections to map grayscale inputs to Lab color channels, optimizing realism through L1 loss minimization.
      - Processed large-scale image data from the COCO dataset with custom OpenCV pipelines and PyTorch DataLoaders, enhancing preprocessing efficiency and model throughput.
      - Built a Flask web app with HTML/CSS frontend to deliver real-time image colorization through a clean and interactive user interface.
      - Managed model inference, image postprocessing, and file handling in a modular backend architecture, supporting smooth user uploads and downloads.
      - Ensured modular code design, version control, and reproducibility through well-structured GitHub repository and training-validation workflow separation.
